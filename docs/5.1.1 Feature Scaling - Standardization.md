**Status:**  #Complete 
**Tags:**    [[Data Preprocessing]]  [[Feature Engineering]] [[Feature Scaling]]
## Feature Scaling

Feature Scaling is a technique to standardize the independent features present in the data to a fixed range.

### Types of Feature Scaling:

1. **Standardization (Z-score normalization)**
2. **Normalization (Min-Max Scaling)**
3. **Robust Scaling**

---

### Standardization (Z-score normalization)

**Code Implementation:**

```python
import numpy as np  # linear algebra
import pandas as pd  # data processing
import matplotlib.pyplot as plt
import seaborn as sns
```

#### Loading and Preprocessing Data:

```python
df = pd.read_csv('Social_Network_Ads.csv')
df = df.iloc[:, 2:]
df.sample(5)
```

![[Pasted image 20250125133922.png]]
#### Train-Test Split:

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    df.drop('Purchased', axis=1),
    df['Purchased'],
    test_size=0.3,
    random_state=0
)
X_train.shape, X_test.shape
```

Output:

```
((280, 2), (120, 2))
```

#### StandardScaler:

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

# Fit the scaler to the train set
scaler.fit(X_train)

# Transform train and test sets
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

Scaler Mean:

```python
scaler.mean_
```

Output:

```
array([37.8642857, 69807.14285714])
```

#### Convert Scaled Data to DataFrame:

```python
X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)
```

#### Descriptive Statistics Before and After Scaling:

```python
np.round(X_train.describe(), 1)
```

Output:

![[Pasted image 20250125133943.png]]

```python
np.round(X_train_scaled.describe(), 1)
```

Output:

![[Pasted image 20250125133957.png]]


---

#### Effect of Scaling:

```python
fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))

# Before Scaling
ax1.scatter(X_train['Age'], X_train['EstimatedSalary'])
ax1.set_title("Before Scaling")

# After Scaling
ax2.scatter(X_train_scaled['Age'], X_train_scaled['EstimatedSalary'], color='red')
ax2.set_title("After Scaling")

plt.show()
```
#### Output :

![[Pasted image 20250125133033.png]]

#### KDE Plots for Distributions:

```python
fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))

# Before Scaling
ax1.set_title('Before Scaling')
sns.kdeplot(X_train['Age'], ax=ax1)
sns.kdeplot(X_train['EstimatedSalary'], ax=ax1)

# After Scaling
ax2.set_title('After Standard Scaling')
sns.kdeplot(X_train_scaled['Age'], ax=ax2)
sns.kdeplot(X_train_scaled['EstimatedSalary'], ax=ax2)

plt.show()
```
#### Output :

![[Pasted image 20250125133107.png]]



#### Individual Feature Comparisons:

```python
# Age Distribution
fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))
ax1.set_title('Age Distribution Before Scaling')
sns.kdeplot(X_train['Age'], ax=ax1)
ax2.set_title('Age Distribution After Standard Scaling')
sns.kdeplot(X_train_scaled['Age'], ax=ax2)
plt.show()```
#### Output :

![[Pasted image 20250125133131.png]]

```python
# Salary Distribution
fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))
ax1.set_title('Salary Distribution Before Scaling')
sns.kdeplot(X_train['EstimatedSalary'], ax=ax1)
ax2.set_title('Salary Distribution Standard Scaling')
sns.kdeplot(X_train_scaled['EstimatedSalary'], ax=ax2)
plt.show()
```
#### Output :

![[Pasted image 20250125133156.png]]


---

### Importance of Scaling:

#### Logistic Regression:

```python
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr_scaled = LogisticRegression()

# Train Models
lr.fit(X_train, y_train)
lr_scaled.fit(X_train_scaled, y_train)

# Predictions
y_pred = lr.predict(X_test)
y_pred_scaled = lr_scaled.predict(X_test_scaled)

# Accuracy
from sklearn.metrics import accuracy_score

print("Actual", accuracy_score(y_test, y_pred))
print("Scaled", accuracy_score(y_test, y_pred_scaled))
```

Output:

```
Actual 0.6583333333333333
Scaled 0.8666666666666667
```

#### Decision Tree Classifier:

```python
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()
dt_scaled = DecisionTreeClassifier()

# Train Models
dt.fit(X_train, y_train)
dt_scaled.fit(X_train_scaled, y_train)

# Predictions
y_pred = dt.predict(X_test)
y_pred_scaled = dt_scaled.predict(X_test_scaled)

# Accuracy
print("Actual", accuracy_score(y_test, y_pred))
print("Scaled", accuracy_score(y_test, y_pred_scaled))
```

Output:

```
Actual 0.875
Scaled 0.875
```

---

### Effect of Outliers:

```python
df = df.append(pd.DataFrame({'Age': [5, 90, 95],
                              'EstimatedSalary': [1000, 250000, 350000],
                              'Purchased': [0, 1, 1]}), ignore_index=True)
plt.scatter(df['Age'], df['EstimatedSalary'])
plt.show()
```
#### Output :
![[Pasted image 20250125133510.png]]

```python 
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df.drop('Purchased', axis=1),
                                                    df['Purchased'],
                                                    test_size=0.3,
                                                    random_state=0)

X_train.shape, X_test.shape
```
#### Output :
```
((282, 2), (121, 2))
```

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

# fit the scaler to the train set, it will learn the parameters
scaler.fit(X_train)

# transform train and test sets
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)



X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)


fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))

ax1.scatter(X_train['Age'], X_train['EstimatedSalary'])
ax1.set_title("Before Scaling")
ax2.scatter(X_train_scaled['Age'], X_train_scaled['EstimatedSalary'],color='red')
ax2.set_title("After Scaling")
plt.show()
```
#### Output :

![[Pasted image 20250125133708.png]]

### When to use Standardization?

![[Pasted image 20250125122618.png]]