**Status:**  #Complete 
**Tags:**  [[EDA]]  [[Data Preprocessing]]  [[Feature Engineering]] 
### **Code Explanation & Notes**

This code is for **feature engineering and model evaluation** using logistic regression in a machine learning pipeline. Here's a step-by-step breakdown:

---

### **1. Handling Missing Values**

```python
df.dropna(inplace=True)
```

- **Drops all rows with missing values** to ensure a clean dataset.

---

### **2. Splitting Features (X) and Target (y)**

```python
X = df.iloc[:,0:4]  
y = df.iloc[:,-1]
```

- `X` contains the **first 4 columns** (independent variables).
- `y` contains the **last column** (dependent variable, the target).

---

### **3. Evaluating Initial Model Performance**

```python
np.mean(cross_val_score(LogisticRegression(),X,y,scoring='accuracy',cv=20))
```

- Uses **20-fold cross-validation** to evaluate a **Logistic Regression model** on `X` and `y`.
- Computes **mean accuracy** (`0.6933` or ~69.3%).

---

### **4. Creating a New Feature: `Family_size`**

```python
X['Family_size'] = X['SibSp'] + X['Parch'] + 1
```

- `Family_size` = **Siblings/Spouse (`SibSp`) + Parents/Children (`Parch`) + 1** (including the person).
- Adds a **new column** to `X`.

---

### **5. Defining a Function for Family Type Classification**

```python
def myfunc(num):
    if num == 1:
        return 0  # Alone
    elif num > 1 and num <= 4:
        return 1  # Small Family
    else:
        return 2  # Large Family
```

- **Classifies family sizes**:
    - `0` â†’ Alone
    - `1` â†’ Small family (2-4 members)
    - `2` â†’ Large family (5+ members)

---

### **6. Applying the Function to Create `Family_type`**

```python
X['Family_type'] = X['Family_size'].apply(myfunc)
```

- Uses `.apply(myfunc)` to **categorize** family sizes.

---

### **7. Dropping Redundant Columns**

```python
X.drop(columns=['SibSp','Parch','Family_size'], inplace=True)
```

- Removes `SibSp`, `Parch`, and `Family_size` since they are now **redundant** (replaced by `Family_type`).

---

### **8. Evaluating Model Performance Again**

```python
np.mean(cross_val_score(LogisticRegression(),X,y,scoring='accuracy',cv=20))
```

- Runs **cross-validation again** after feature engineering.
- Compares accuracy with the earlier model.

---

### **Key Takeaways**

âœ” **Feature Engineering**: Created `Family_size` and `Family_type` for better insights.  
âœ” **Feature Selection**: Dropped redundant columns to avoid multicollinearity.  
âœ” **Model Evaluation**: Used cross-validation to assess model performance before and after feature creation.

Would you like to compare the model's accuracy before and after feature engineering? ğŸš€