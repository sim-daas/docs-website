**Status:**  #Complete 
**Tags:**   [[Data Preprocessing]]  [[Feature Engineering]] [[Sklearn]]


```python
  
import numpy as np 
import pandas as pd

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import OrdinalEncoder

df = pd.read_csv('covid_toy.csv')
df.head()

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(df.drop(columns=['has_covid']),df['has_covid'],
                                                test_size=0.2)

from sklearn.compose import ColumnTransformer

transformer = ColumnTransformer(transformers=[
    ('tnf1',SimpleImputer(),['fever']),
    ('tnf2',OrdinalEncoder(categories=[['Mild','Strong']]),['cough']),
    ('tnf3',OneHotEncoder(sparse=False,drop='first'),['gender','city'])
],remainder='passthrough')

```

---
### 1. **Import Libraries**

```python
import numpy as np 
import pandas as pd

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import OrdinalEncoder
```

- **`numpy` and `pandas`**: Used for numerical computations and data manipulation.
- **`SimpleImputer`**: Handles missing values in a dataset by imputing (filling) them.
- **`OneHotEncoder`**: Converts categorical variables into binary or one-hot encoded format.
- **`OrdinalEncoder`**: Converts ordinal categorical variables (with a meaningful order) into numerical format.

---

### 2. **Load the Dataset**

```python
df = pd.read_csv('covid_toy.csv')
df.head()
```

![[Pasted image 20250125163913.png]]

- **`pd.read_csv`**: Reads a CSV file (`covid_toy.csv`) into a pandas DataFrame.
- **`df.head()`**: Displays the first 5 rows of the dataset for a quick preview.

---

### 3. **Split the Dataset**

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    df.drop(columns=['has_covid']),
    df['has_covid'],
    test_size=0.2
)
```

- **`train_test_split`**:
    - Splits the dataset into training and testing sets.
    - **`df.drop(columns=['has_covid'])`**: Excludes the target column (`has_covid`) from the features (`X_train` and `X_test`).
    - **`df['has_covid']`**: The target variable (`y_train` and `y_test`).
    - **`test_size=0.2`**: Allocates 20% of the data to the test set and 80% to the training set.

---

### 4. **Define a `ColumnTransformer`**

```python
from sklearn.compose import ColumnTransformer

transformer = ColumnTransformer(transformers=[
    ('tnf1', SimpleImputer(), ['fever']),
    ('tnf2', OrdinalEncoder(categories=[['Mild', 'Strong']]), ['cough']),
    ('tnf3', OneHotEncoder(sparse=False, drop='first'), ['gender', 'city'])
], remainder='passthrough')
```

The **`ColumnTransformer`** applies specific transformations to different columns in a single step:

- **Transformers**: A list of tuples with the format `(name, transformer, columns)`:
    1. **`tnf1` (SimpleImputer)**:
        - Handles missing values in the `fever` column.
        - Automatically fills missing values (e.g., with the mean or median, depending on the default or specified strategy).
    2. **`tnf2` (OrdinalEncoder)**:
        - Encodes the `cough` column based on the order `['Mild', 'Strong']`.
            - `Mild` is encoded as `0`, and `Strong` is encoded as `1`.
    3. **`tnf3` (OneHotEncoder)**:
        - Applies one-hot encoding to `gender` and `city`.
        - **`sparse=False`**: Returns a dense array (instead of a sparse matrix).
        - **`drop='first'`**: Drops the first category to avoid multicollinearity (e.g., for `gender`, only "Male" is represented numerically as `0` or `1`).
- **`remainder='passthrough'`**:
    - Keeps all columns that are not explicitly transformed as-is (e.g., `age`).

---

### What the `transformer` does:

1. Fills missing values in the `fever` column.
2. Encodes the `cough` column as `0` or `1`.
3. Converts `gender` and `city` into one-hot encoded columns (dropping the first category for each).
4. Leaves other columns untouched and includes them in the final transformed dataset.

This `transformer` can be applied to the training and test datasets to ensure consistent preprocessing.