## Overview

Gradient Descent is an optimization algorithm used to minimize a function by iteratively moving towards the minimum value of the function. It is widely used in machine learning and deep learning to optimize models by minimizing the loss function.

---

## Key Concepts

### 1. **Objective**

- Minimize a **cost function** (or loss function) by finding the optimal parameters (weights) of a model.

### 2. **How It Works**

- Start with an initial guess for the parameters.
- Compute the gradient (derivative) of the cost function with respect to the parameters.
- Update the parameters in the opposite direction of the gradient.
- Repeat until convergence (i.e., the gradient is close to zero).

### 3. **Mathematical Formulation**

- The update rule for parameters θ\theta is: θnew=θold−α⋅∇J(θ)\theta_{\text{new}} = \theta_{\text{old}} - \alpha \cdot \nabla J(\theta) Where:
    - θ\theta: Parameters (e.g., weights in a model).
    - α\alpha: Learning rate (step size).
    - ∇J(θ)\nabla J(\theta): Gradient of the cost function J(θ)J(\theta).

---

## Types of Gradient Descent

### 1. **Batch Gradient Descent**

- Computes the gradient using the entire dataset.
- **Pros**: Stable convergence.
- **Cons**: Computationally expensive for large datasets.

### 2. **Stochastic Gradient Descent (SGD)**

- Computes the gradient using a single data point at a time.
- **Pros**: Faster updates, can escape local minima.
- **Cons**: Noisy updates, less stable convergence.

### 3. **Mini-Batch Gradient Descent**

- Computes the gradient using a small subset (mini-batch) of the dataset.
- **Pros**: Balances speed and stability.
- **Cons**: Requires tuning of batch size.

---

## Learning Rate

- The learning rate α\alpha controls the step size of each update.
- **Too high**: May overshoot the minimum.
- **Too low**: Slow convergence.

---

## Challenges

1. **Local Minima**
    - Gradient Descent can get stuck in local minima (especially in non-convex functions).
2. **Saddle Points**
    - Points where the gradient is zero but not a minimum.
3. **Vanishing/Exploding Gradients**
    - Common in deep neural networks.

---

## Improvements

4. **Momentum**
    - Adds a fraction of the previous update to the current update to accelerate convergence.
5. **Adaptive Learning Rates**
    - Algorithms like **Adam**, **RMSprop**, and **Adagrad** adjust the learning rate dynamically.
6. **Learning Rate Schedules**
    - Gradually reduce the learning rate over time.

---

## Applications

- Training machine learning models (e.g., linear regression, neural networks).
- Solving optimization problems in various fields (e.g., physics, economics).

---

## Example (Python)

```python
import numpy as np

# Define a simple cost function (e.g., MSE)
def cost_function(theta, X, y):
    m = len(y)
    predictions = X.dot(theta)
    return (1/(2*m)) * np.sum((predictions - y)**2)

# Gradient of the cost function
def gradient(theta, X, y):
    m = len(y)
    predictions = X.dot(theta)
    return (1/m) * X.T.dot(predictions - y)

# Gradient Descent
def gradient_descent(X, y, theta, alpha, iterations):
    for _ in range(iterations):
        theta = theta - alpha * gradient(theta, X, y)
    return theta

# Example usage
X = np.array([[1, 1], [1, 2], [1, 3]])
y = np.array([1, 2, 3])
theta = np.zeros(X.shape[1])
alpha = 0.01
iterations = 1000
theta = gradient_descent(X, y, theta, alpha, iterations)
print("Optimized parameters:", theta)
```

---

## Related Topics

- [[Optimization Algorithms]]
- [[Stochastic Gradient Descent]]
- [[Backpropagation]]
- [[Loss Functions]]

---

## References

- [Deep Learning by Ian Goodfellow](https://www.deeplearningbook.org/)
- [Machine Learning by Andrew Ng](https://www.coursera.org/learn/machine-learning)